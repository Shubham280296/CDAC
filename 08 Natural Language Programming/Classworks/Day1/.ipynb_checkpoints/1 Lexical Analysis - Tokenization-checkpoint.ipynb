{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f3a2c2",
   "metadata": {},
   "source": [
    "## Library installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abb4287",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk spacy textblob -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6dd0863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0211611c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package indian to C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package indian is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') ## tokenization\n",
    "nltk.download('stopwords') ## stopwords removal\n",
    "nltk.download('averaged_perceptron_tagger') ## part of speech (speech) tagging\n",
    "nltk.download('wordnet') ## wordnet database and lemmatization\n",
    "nltk.download('omw-1.4') ## stemmin\n",
    "nltk.download('indian') ## Indian language pos tagging\n",
    "nltk.download('maxent_ne_chunker') ## chunkingh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b696b63b",
   "metadata": {},
   "source": [
    "## Sample example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cf94c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the average of ages mentioned in the above sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ff92ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.666666666666668\n"
     ]
    }
   ],
   "source": [
    "sent = 'They told that their ages are 25   27 and 31 respectively.'\n",
    "ages = []\n",
    "\n",
    "for i in sent.split(\" \"):\n",
    "    if i.isdigit():\n",
    "        ages.append(int(i))\n",
    "        \n",
    "print(sum(ages)/len(ages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54b0ffcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.666666666666668\n"
     ]
    }
   ],
   "source": [
    "ages = [int(word) for word in sent.split() if word.isdigit()]\n",
    "print(sum(ages)/len(ages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b750d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.666666666666668"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean([int(word) for word in sent.split() if word.isdigit()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c8caf0",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45af25ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'Hello friends! How are you? Welcome to Python Programming.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43d049db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the functions for tokenization\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e66e07ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello friends!', 'How are you?', 'Welcome to Python Programming.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#segmentation\n",
    "sent_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1eea05e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'friends',\n",
       " '!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'Python',\n",
       " 'Programming',\n",
       " '.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3eae45b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0\n"
     ]
    }
   ],
   "source": [
    "# Find the percentage of punctuation symbols present in it\n",
    "\n",
    "count =0\n",
    "\n",
    "for i in word_tokenize(sent):\n",
    "    if i.isalnum():\n",
    "        count +=1\n",
    "        \n",
    "print((1-(count/len(word_tokenize(sent))))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bf3ba9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct_count = len([word for word in word_tokenize(sent) if not word.isalnum()])\n",
    "punct_count/len(word_tokenize(sent))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d29f05",
   "metadata": {},
   "source": [
    "## Ascii code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fe2ed43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('#') # get ascii value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7aa81035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof('#')  ## min size of object is 50 in ascii though only 8 are used for one char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f6cd3a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof('abcdfgh') ## 8*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f216c629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'K'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(75) ## returns character associated with number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466aa906",
   "metadata": {},
   "source": [
    "## Universal Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "424423fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "व\n"
     ]
    }
   ],
   "source": [
    "char = '\\u0935' ## universal code\n",
    "print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cbee5c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "वी\n"
     ]
    }
   ],
   "source": [
    "char = '\\u0935\\u0940'\n",
    "print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e3994bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'श'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(2358)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "813eb546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'व'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0x935) # hexadecimal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a01c5314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof('व') ## min size of object is 76 in universal though only 8 are used for one char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bf33facb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['शुभम', 'शहा']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'शुभम शहा'\n",
    "name.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a4327b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.startswith('श')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3d797b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'वुभम वहा'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.replace('श', 'व')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "23ae9716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.find('म')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a8b85701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8aadccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ु'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1f75df",
   "metadata": {},
   "source": [
    "## Text in regional languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b2d959",
   "metadata": {},
   "source": [
    "mytext = '४८ कि. मी. अंतरावर आणि पुणे जिल्ह्यातील वेल्हे तालुक्यात व भोर गावाच्या वायव्येला २४ कि.मी. अंतरावर नीरा-वेळवंडी-कानंदी आणि गुंजवणी या नद्यांच्या खोऱ्यांच्या बेचक्यात मुरुंबदेवाचा डोंगर उभा आहे. मावळ भागामध्ये राज्यविस्तार साध्य करण्यासाठी राजगड आणि तोरणा हे दोन्ही किल्ले मोक्याच्या ठिकाणी होते. तोरणा Archived 2020-09-20 at the Wayback Machine. किल्ल्याचा बालेकिल्ला आकाराने लहान असल्यामुळे राजकीय केंद्र म्हणून हा किल्ला सोयीचा नव्हता. त्यामानाने राजगड दुर्गम असून त्याचा बालेकिल्ला बराच मोठा आहे. शिवाय राजगडाकडे कोणत्याही बाजूने येताना एखादी टेकडी किंवा नदी ओलांडावीच लागते. एवढी सुरक्षितता होती,म्हणून आपले राजकीय केंद्र म्हणून शिवाजी महाराजांनी Archived 2020-03-18 at the Wayback Machine. राजगडाची निवड केली. राजगडाला तीन माच्या व एक बालेकिल्ला आहे. राजगडचा बालेकिल्ला खूप उंच असून त्याची समुद्रसपाटीपासूनची उंची १३९४ मीटर आहे. दुर्गराज राजगड त्यांच्या महत्त्वाकांक्षेची उंची दाखवतो, तर किल्ले रायगड हा शिवाजी महाराजांच्या कर्तृत्वाचा विस्तार दाखवतो. राजगडाच्या मध्यवर्ती ठिकाणी उंच डोंगर तासून तयार केलेला बालेकिल्ला म्हणजे पृथ्वीने स्वर्गावर केलेली स्वारी होय.'\n",
    "mytext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ac81d184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['४८',\n",
       " 'कि',\n",
       " '.',\n",
       " 'मी',\n",
       " '.',\n",
       " 'अंतरावर',\n",
       " 'आणि',\n",
       " 'पुणे',\n",
       " 'जिल्ह्यातील',\n",
       " 'वेल्हे',\n",
       " 'तालुक्यात',\n",
       " 'व',\n",
       " 'भोर',\n",
       " 'गावाच्या',\n",
       " 'वायव्येला',\n",
       " '२४',\n",
       " 'कि.मी',\n",
       " '.',\n",
       " 'अंतरावर',\n",
       " 'नीरा-वेळवंडी-कानंदी',\n",
       " 'आणि',\n",
       " 'गुंजवणी',\n",
       " 'या',\n",
       " 'नद्यांच्या',\n",
       " 'खोऱ्यांच्या',\n",
       " 'बेचक्यात',\n",
       " 'मुरुंबदेवाचा',\n",
       " 'डोंगर',\n",
       " 'उभा',\n",
       " 'आहे',\n",
       " '.',\n",
       " 'मावळ',\n",
       " 'भागामध्ये',\n",
       " 'राज्यविस्तार',\n",
       " 'साध्य',\n",
       " 'करण्यासाठी',\n",
       " 'राजगड',\n",
       " 'आणि',\n",
       " 'तोरणा',\n",
       " 'हे',\n",
       " 'दोन्ही',\n",
       " 'किल्ले',\n",
       " 'मोक्याच्या',\n",
       " 'ठिकाणी',\n",
       " 'होते',\n",
       " '.',\n",
       " 'तोरणा',\n",
       " 'Archived',\n",
       " '2020-09-20',\n",
       " 'at',\n",
       " 'the',\n",
       " 'Wayback',\n",
       " 'Machine',\n",
       " '.',\n",
       " 'किल्ल्याचा',\n",
       " 'बालेकिल्ला',\n",
       " 'आकाराने',\n",
       " 'लहान',\n",
       " 'असल्यामुळे',\n",
       " 'राजकीय',\n",
       " 'केंद्र',\n",
       " 'म्हणून',\n",
       " 'हा',\n",
       " 'किल्ला',\n",
       " 'सोयीचा',\n",
       " 'नव्हता',\n",
       " '.',\n",
       " 'त्यामानाने',\n",
       " 'राजगड',\n",
       " 'दुर्गम',\n",
       " 'असून',\n",
       " 'त्याचा',\n",
       " 'बालेकिल्ला',\n",
       " 'बराच',\n",
       " 'मोठा',\n",
       " 'आहे',\n",
       " '.',\n",
       " 'शिवाय',\n",
       " 'राजगडाकडे',\n",
       " 'कोणत्याही',\n",
       " 'बाजूने',\n",
       " 'येताना',\n",
       " 'एखादी',\n",
       " 'टेकडी',\n",
       " 'किंवा',\n",
       " 'नदी',\n",
       " 'ओलांडावीच',\n",
       " 'लागते',\n",
       " '.',\n",
       " 'एवढी',\n",
       " 'सुरक्षितता',\n",
       " 'होती',\n",
       " ',',\n",
       " 'म्हणून',\n",
       " 'आपले',\n",
       " 'राजकीय',\n",
       " 'केंद्र',\n",
       " 'म्हणून',\n",
       " 'शिवाजी',\n",
       " 'महाराजांनी',\n",
       " 'Archived',\n",
       " '2020-03-18',\n",
       " 'at',\n",
       " 'the',\n",
       " 'Wayback',\n",
       " 'Machine',\n",
       " '.',\n",
       " 'राजगडाची',\n",
       " 'निवड',\n",
       " 'केली',\n",
       " '.',\n",
       " 'राजगडाला',\n",
       " 'तीन',\n",
       " 'माच्या',\n",
       " 'व',\n",
       " 'एक',\n",
       " 'बालेकिल्ला',\n",
       " 'आहे',\n",
       " '.',\n",
       " 'राजगडचा',\n",
       " 'बालेकिल्ला',\n",
       " 'खूप',\n",
       " 'उंच',\n",
       " 'असून',\n",
       " 'त्याची',\n",
       " 'समुद्रसपाटीपासूनची',\n",
       " 'उंची',\n",
       " '१३९४',\n",
       " 'मीटर',\n",
       " 'आहे',\n",
       " '.',\n",
       " 'दुर्गराज',\n",
       " 'राजगड',\n",
       " 'त्यांच्या',\n",
       " 'महत्त्वाकांक्षेची',\n",
       " 'उंची',\n",
       " 'दाखवतो',\n",
       " ',',\n",
       " 'तर',\n",
       " 'किल्ले',\n",
       " 'रायगड',\n",
       " 'हा',\n",
       " 'शिवाजी',\n",
       " 'महाराजांच्या',\n",
       " 'कर्तृत्वाचा',\n",
       " 'विस्तार',\n",
       " 'दाखवतो',\n",
       " '.',\n",
       " 'राजगडाच्या',\n",
       " 'मध्यवर्ती',\n",
       " 'ठिकाणी',\n",
       " 'उंच',\n",
       " 'डोंगर',\n",
       " 'तासून',\n",
       " 'तयार',\n",
       " 'केलेला',\n",
       " 'बालेकिल्ला',\n",
       " 'म्हणजे',\n",
       " 'पृथ्वीने',\n",
       " 'स्वर्गावर',\n",
       " 'केलेली',\n",
       " 'स्वारी',\n",
       " 'होय',\n",
       " '.']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(mytext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9f8944",
   "metadata": {},
   "source": [
    "## Read file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f19f211b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello Friends! How are you?\\n', 'Welcome to the world of Python Programming.']\n"
     ]
    }
   ],
   "source": [
    "with open(\"mydata.txt\") as myfile:\n",
    "    print(myfile.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "417aef4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Friends! \tHow are you?\n",
      "Welcome to the world of \tPython Programming.\n"
     ]
    }
   ],
   "source": [
    "myfile = open(\"mydata.txt\",'r') \n",
    "data = myfile.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2984f862",
   "metadata": {},
   "source": [
    "### Space tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0e002107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Friends!',\n",
       " '\\tHow',\n",
       " 'are',\n",
       " 'you?\\nWelcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " '\\tPython',\n",
       " 'Programming.']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import SpaceTokenizer ## only space is used for tokenizing\n",
    "\n",
    "## create an object\n",
    "tk = SpaceTokenizer()\n",
    "\n",
    "## tokenize the data\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956b5b92",
   "metadata": {},
   "source": [
    "### Tab tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "00c4c6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello Friends! ',\n",
       " 'How are you?\\nWelcome to the world of ',\n",
       " 'Python Programming.']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TabTokenizer ## only tab is used for tokenizing\n",
    "\n",
    "## create an object\n",
    "tk = TabTokenizer()\n",
    "\n",
    "## tokenize the data\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4706bb9",
   "metadata": {},
   "source": [
    "### Line tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d06eaa62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello Friends! \\tHow are you?',\n",
       " 'Welcome to the world of \\tPython Programming.']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import LineTokenizer ## only \\n is used for tokenizing\n",
    "\n",
    "## create an object\n",
    "tk = LineTokenizer()\n",
    "\n",
    "## tokenize the data\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86167bf",
   "metadata": {},
   "source": [
    "### White space tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a950330b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Friends!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'Python',\n",
       " 'Programming.']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer ## all spaces, tabs and \\n are used for tokenizing\n",
    "\n",
    "## create an object\n",
    "tk = WhitespaceTokenizer()\n",
    "\n",
    "## tokenize the data\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db76cff4",
   "metadata": {},
   "source": [
    "### MWE tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "32fb33f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Van Rossum is Python creator, visiting Pune this week. The \n",
      "developement community is eager to meet Van Rossum\n",
      "['The', 'Van', 'Rossum', 'is', 'Python', 'creator', ',', 'visiting', 'Pune', 'this', 'week', '.', 'The', 'developement', 'community', 'is', 'eager', 'to', 'meet', 'Van', 'Rossum']\n"
     ]
    }
   ],
   "source": [
    "sent1 = '''The Van Rossum is Python creator, visiting Pune this week. The \n",
    "developement community is eager to meet Van Rossum'''\n",
    "\n",
    "print(sent1)\n",
    "\n",
    "print(word_tokenize(sent1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0847fc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Van Rossum',\n",
       " 'is',\n",
       " 'Python',\n",
       " 'creator',\n",
       " ',',\n",
       " 'visiting',\n",
       " 'Pune',\n",
       " 'this',\n",
       " 'week',\n",
       " '.',\n",
       " 'The',\n",
       " 'developement',\n",
       " 'community',\n",
       " 'is',\n",
       " 'eager',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'Van Rossum']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import MWETokenizer ## always gives output with multiword expression as single token \n",
    "                                        # seperated by a seperator(defaults = '_') for an input from other tokenizer\n",
    "\n",
    "## create an object\n",
    "tk = MWETokenizer(separator=' ')\n",
    "\n",
    "## add mutli word expression\n",
    "tk.add_mwe(('Van', 'Rossum'))\n",
    "\n",
    "## tokenize the data\n",
    "tk.tokenize(word_tokenize(sent1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2f8779",
   "metadata": {},
   "source": [
    "### Tweet tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ed0e88ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Friends',\n",
       " ':)',\n",
       " '!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'Python',\n",
       " 'Programming',\n",
       " '.',\n",
       " ':D',\n",
       " ':|',\n",
       " ':',\n",
       " 'O']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Hello Friends :)! How are you? Welcome to the world of Python Programming. :D :|'\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer ## gives word tokenized with emojis as tokens\n",
    "\n",
    "## create an object\n",
    "tk = TweetTokenizer()\n",
    "\n",
    "## tokenize the data\n",
    "tk.tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5c4ebbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Friends 😀! \tHow are you?🤚\n",
      "Welcome 🙏 to the world🌍 of \tPython 💻Programming.\n"
     ]
    }
   ],
   "source": [
    "f = open(\"mydata1.txt\",encoding='utf-8') \n",
    "data = f.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cef10f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Friends',\n",
       " '😀',\n",
       " '!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " '🤚',\n",
       " 'Welcome',\n",
       " '🙏',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world🌍',\n",
       " 'of',\n",
       " 'Python',\n",
       " '💻Programming',\n",
       " '.']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9c8be442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Friends',\n",
       " '😀',\n",
       " '!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " '🤚',\n",
       " 'Welcome',\n",
       " '🙏',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " '🌍',\n",
       " 'of',\n",
       " 'Python',\n",
       " '💻',\n",
       " 'Programming',\n",
       " '.']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## tokenize the data\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd717c16",
   "metadata": {},
   "source": [
    "### Custom tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a2a26d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens : \n",
      "Th\n",
      "s\n",
      "s\n",
      "some\n",
      "text\n",
      "w\n",
      "th\n",
      "punctuat\n",
      "on\n",
      ">\n",
      "Let's\n",
      "token\n",
      "ze\n",
      "t\n",
      "Is\n",
      "t\n",
      "ok\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    return re.split(r\"[.,:?!\\s]+\", text)\n",
    "\n",
    "text = \"This is some text with punctuation > Let's tokenize it. Is it ok?\"\n",
    "\n",
    "tokens = custom_tokenizer(text)\n",
    "\n",
    "print(\"Tokens : \")\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d085eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## mitu.co.in/dataset/student3.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fbd6771f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roll\tname\tclass\tmarks\tage\n",
      "1\tanil\tTE\t56.77\t22\n",
      "2\tamit\tTE\t59.77\t21\n",
      "3\taniket\tBE\t76.88\t19\n",
      "4\tajinkya\tTE\t69.66\t20\n",
      "5\tasha\tTE\t63.28\t20\n",
      "6\tayesha\tBE\t49.55\t20\n",
      "7\tamar\tBE\t65.34\t19\n",
      "8\tamita\tBE\t68.33\t23\n",
      "9\tamol\tTE\t56.75\t20\n",
      "10\tanmol\tBE\t78.66\t21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('student3.tsv')\n",
    "data = f.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8b98af25",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "\n",
    "for i in data.split('\\n'):\n",
    "    sublist = []\n",
    "    for j in i.split('\\t'):\n",
    "        if j.isdigit():\n",
    "            sublist.append(int(j))\n",
    "        elif '.' in(j):\n",
    "            sublist.append(float(j))\n",
    "        else:\n",
    "            sublist.append(j)\n",
    "    list.append(sublist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bc669644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'anil', 'TE', 56.77, 22],\n",
       " [2, 'amit', 'TE', 59.77, 21],\n",
       " [3, 'aniket', 'BE', 76.88, 19],\n",
       " [4, 'ajinkya', 'TE', 69.66, 20],\n",
       " [5, 'asha', 'TE', 63.28, 20],\n",
       " [6, 'ayesha', 'BE', 49.55, 20],\n",
       " [7, 'amar', 'BE', 65.34, 19],\n",
       " [8, 'amita', 'BE', 68.33, 23],\n",
       " [9, 'amol', 'TE', 56.75, 20],\n",
       " [10, 'anmol', 'BE', 78.66, 21]]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc1e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
