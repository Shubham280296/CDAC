{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "679Lmwt3l1Bk"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Vq1MaJI-4uF"
   },
   "source": [
    "# CNN\n",
    "\n",
    "\n",
    "##  Flower Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iAve6DCL4JH4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###-----------------\n",
    "### Import Libraries\n",
    "###-----------------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils.helper import fn_plot_tf_hist,fn_plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0QFsplWU-4uH"
   },
   "outputs": [],
   "source": [
    "###----------------------\n",
    "### Some basic parameters\n",
    "###----------------------\n",
    "inpDir = '../..\\Classwork/input'\n",
    "outDir = './output'\n",
    "subDir = 'flower_photos'\n",
    "modelDir = './models'\n",
    "logDir = './logs'\n",
    "altName = 'cnn_base'\n",
    "\n",
    "RANDOM_STATE = 24 # for initialization ----- REMEMBER: to remove at the time of promotion to production\n",
    "tf.random.set_seed(RANDOM_STATE) # setting for Tensorflow as well\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "ALPHA = 0.001\n",
    "EPOCHS = 200 # number of cycles to run\n",
    "PATIENCE = 20\n",
    "LR_PATIENCE = 10\n",
    "FACTOR_LR = 0.1\n",
    "BATCH_SIZE = 16 # inline of Training Rows being 60000\n",
    "IMG_HEIGHT = 227\n",
    "IMG_WIDTH = 227\n",
    "\n",
    "\n",
    "# Set parameters for decoration of plots\n",
    "params = {'legend.fontsize' : 'large',\n",
    "          'figure.figsize'  : (15,10),\n",
    "          'axes.labelsize'  : 'x-large',\n",
    "          'axes.titlesize'  :'x-large',\n",
    "          'xtick.labelsize' :'large',\n",
    "          'ytick.labelsize' :'large',\n",
    "         }\n",
    "\n",
    "CMAP = plt.cm.coolwarm\n",
    "\n",
    "plt.rcParams.update(params) # update rcParams\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid') # plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMLb0J4lEnjO"
   },
   "source": [
    "## Basic Hygiene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yL2JOjK4-4uI"
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xm66whGj_nrn",
    "outputId": "dca7d8d8-6862-4b49-88bc-8eb8013e1dac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print (physical_devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qbHlymTEdxG"
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "x2uh0xZm-4uJ",
    "outputId": "67ab73a8-e290-4167-aff5-e22e047ac7c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../..\\\\Classwork/input\\\\flower_photos'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "\n",
    "data_dir = tf.keras.utils.get_file(origin=dataset_url,\n",
    "                                   fname='flower_photos',\n",
    "                                   untar=True)\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "'''\n",
    "data_dir = os.path.join(inpDir, subDir)\n",
    "data_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bcebwqcw-4uK",
    "outputId": "227a647a-4cc7-4efa-a8fe-14915752bd03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daisy', 'dandelion', 'LICENSE.txt', 'roses', 'sunflowers', 'tulips']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dMpgmBvErj2"
   },
   "source": [
    "## Creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J8Shk8Fi-4uL",
    "outputId": "8e654aec-a9f1-442c-abf5-1df91814ab81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2936 files for training.\n",
      "Found 3670 files belonging to 5 classes.\n",
      "Using 734 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# create training data\n",
    "train_ds =tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir, # path the the data directory\n",
    "    validation_split=TEST_SIZE, # what ratio of validation data\n",
    "    subset='training', # purpose\n",
    "    seed=RANDOM_STATE,\n",
    "    image_size=[IMG_HEIGHT, IMG_WIDTH], ## @@@ WHAT!\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "# test data\n",
    "test_ds =tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir, # path the the data directory\n",
    "    validation_split=TEST_SIZE, # what ratio of validation data\n",
    "    subset='validation', # purpose\n",
    "    seed=RANDOM_STATE,\n",
    "    image_size=[IMG_HEIGHT, IMG_WIDTH], ## @@@ WHAT!\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FP9Jk9Lf-4uL",
    "outputId": "ebd8967f-64ca-4c85-a602-3e6dfb80c504"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is it picking class names\n",
    "class_names = train_ds.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CbxIr7tRAhOj",
    "outputId": "74f0d873-0032-4312-8095-365b62668188"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'daisy', 1: 'dandelion', 2: 'roses', 3: 'sunflowers', 4: 'tulips'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = {k:v for k,v in enumerate(class_names)}\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQ-gvaS-EvN9"
   },
   "source": [
    "## Visualize data in train_ds and test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "klChSP0b-4uM",
    "outputId": "c58fd433-4923-4815-f9ff-694776a12ec7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure(figsize=(15,8))\\n\\nfor images, labels in train_ds.take(1):\\n    for i in range (BATCH_SIZE):\\n        plt.subplot(int(BATCH_SIZE/8), 8, i +1)\\n        plt.grid(False)\\n        plt.imshow(images[i].numpy().astype('uint8'))\\n        plt.title(class_names[labels[i]])\\n        plt.axis('off')\\n    plt.tight_layout()\\nplt.show()\\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range (BATCH_SIZE):\n",
    "        plt.subplot(int(BATCH_SIZE/8), 8, i +1)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i].numpy().astype('uint8'))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "b97a_uKg-4uM",
    "outputId": "085058e3-0241-4cf7-812f-2e23440e55fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure(figsize=(15,8))\\n\\nfor images, labels in test_ds.take(1): # get me one batch\\n\\n    for i in range (BATCH_SIZE): # loop over batch\\n\\n        plt.subplot(int(BATCH_SIZE/8), 8, i +1) # access the axis\\n\\n        plt.grid(False) # no to grid\\n\\n        plt.imshow(images[i].numpy().astype('uint8')) # show image convert to numpy and int\\n\\n        plt.title(class_names[labels[i]])\\n\\n        plt.axis('off')\\n\\n    plt.tight_layout()\\n\\nplt.show()\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "for images, labels in test_ds.take(1): # get me one batch\n",
    "\n",
    "    for i in range (BATCH_SIZE): # loop over batch\n",
    "\n",
    "        plt.subplot(int(BATCH_SIZE/8), 8, i +1) # access the axis\n",
    "\n",
    "        plt.grid(False) # no to grid\n",
    "\n",
    "        plt.imshow(images[i].numpy().astype('uint8')) # show image convert to numpy and int\n",
    "\n",
    "        plt.title(class_names[labels[i]])\n",
    "\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAodZH89EzY2"
   },
   "source": [
    "## To check whether data is balanced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "6C862mXf-4uI",
    "outputId": "cd94477f-3af5-478f-a398-473c25be7c9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef fn_plot_label(tr_ds, ts_ds):\\n\\n    plt.figure(figsize = (15,5)) # instantiate the figure\\n\\n    plt.subplot(1,2,1) # first out of 2\\n\\n    train_labels = tf.concat([lbl for img, lbl in tr_ds], axis = 0).numpy() # get the labels\\n\\n    unique, _, counts = tf.unique_with_counts(train_labels) # get counts\\n\\n    plt.bar(range(len(unique)), counts, align='center', color = 'DarkBlue') # barplot the counts\\n\\n    plt.xticks(range(len(unique)), class_names)\\n\\n    plt.title('Training Set')\\n\\n    plt.subplot(1,2,2)\\n\\n    test_labels = tf.concat([lbl for img, lbl in ts_ds], axis = 0).numpy()\\n\\n    unique, _, counts = tf.unique_with_counts(test_labels)\\n\\n    plt.bar(range(len(unique)), counts, align='center', color = 'Orange')\\n\\n    plt.xticks(range(len(unique)), class_names)\\n\\n    plt.title('Test Set')\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def fn_plot_label(tr_ds, ts_ds):\n",
    "\n",
    "    plt.figure(figsize = (15,5)) # instantiate the figure\n",
    "\n",
    "    plt.subplot(1,2,1) # first out of 2\n",
    "\n",
    "    train_labels = tf.concat([lbl for img, lbl in tr_ds], axis = 0).numpy() # get the labels\n",
    "\n",
    "    unique, _, counts = tf.unique_with_counts(train_labels) # get counts\n",
    "\n",
    "    plt.bar(range(len(unique)), counts, align='center', color = 'DarkBlue') # barplot the counts\n",
    "\n",
    "    plt.xticks(range(len(unique)), class_names)\n",
    "\n",
    "    plt.title('Training Set')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "\n",
    "    test_labels = tf.concat([lbl for img, lbl in ts_ds], axis = 0).numpy()\n",
    "\n",
    "    unique, _, counts = tf.unique_with_counts(test_labels)\n",
    "\n",
    "    plt.bar(range(len(unique)), counts, align='center', color = 'Orange')\n",
    "\n",
    "    plt.xticks(range(len(unique)), class_names)\n",
    "\n",
    "    plt.title('Test Set')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "A6hRkrIp-4uN"
   },
   "outputs": [],
   "source": [
    "# fn_plot_label(train_ds, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0PW-0DJE68-"
   },
   "source": [
    "## Model Building\n",
    "\n",
    "from last conv layer to input layer\n",
    "\n",
    "op size 2*2\n",
    "\n",
    "1. conv layer f = 3, stride (s) =1  ip size = 4*4                        \n",
    "2. maxpool layer f = 2,2, stride (s) =2  ip size = 8*8\n",
    "3. conv layer f = 3, stride (s) =1  ip size = 10*10\n",
    "4. maxpool layer f = 2,2, stride (s) =2  ip size = 20*20\n",
    "5. conv layer f = 3, stride (s) =1  ip size = 22*22\n",
    "6. maxpool layer f = 2,2, stride (s) =2  ip size = 44*44\n",
    "7. conv layer f = 3, stride (s) =1  ip size = 46*46\n",
    "8. maxpool layer f = 2,2, stride (s) =2  ip size = 92*92\n",
    "9. conv layer f = 3, stride (s) =1  ip size = 94*94\n",
    "10. maxpool layer f = 2,2, stride (s) =2  ip size = 188*188\n",
    "11. conv layer f = 3, stride (s) =1  ip size = 190*190  (image size)\n",
    "\n",
    "6 conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4izZWt8-4uN",
    "outputId": "0d640a66-7efa-476c-a08d-817a727870b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((227, 227, 3), 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "num_classes = len(class_names)\n",
    "input_shape, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "v5SgPGyt-4uN"
   },
   "outputs": [],
   "source": [
    "def build_model (input_shape, num_classes):\n",
    "\n",
    "    krnl_initializer = tf.keras.initializers.GlorotUniform(seed = RANDOM_STATE)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    ## increasing dropout rate\n",
    "    drop1 = 0.1\n",
    "    drop2 = 0.2\n",
    "    drop3 = 0.3\n",
    "    drop4 = 0.4\n",
    "    drop5 = 0.5\n",
    "    drop6 = 0.5\n",
    "\n",
    "    ## preprocessing (scaling)\n",
    "    model.add(tf.keras.layers.Rescaling(1./255.))\n",
    "\n",
    "    ## Augmentation\n",
    "\n",
    "    model.add(tf.keras.layers.RandomRotation((-0.5,0.5), fill_mode = 'nearest', seed=RANDOM_STATE))\n",
    "    model.add(tf.keras.layers.RandomFlip((0.2,0.2), fill_mode = 'nearest', seed=RANDOM_STATE))\n",
    "\n",
    "    ## 1 layer\n",
    "    model.add(tf.keras.layers.Conv2D(96,(11,11),\n",
    "                                   strides=(4, 4),\n",
    "                                   padding='valid',\n",
    "                                   kernel_initializer = krnl_initializer,\n",
    "                                   input_shape =input_shape)) ## output shape expected - 55*55*96\n",
    "\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(3,3),strides=2)) ## 27*27*96\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(drop1))\n",
    "\n",
    "    ## 2 layer\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(256,5,\n",
    "                                   padding='same',\n",
    "                                   kernel_initializer = krnl_initializer)) ## output shape expected - 27*27*256\n",
    "\n",
    "\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(3,3),strides=2)) ## 13*13*256\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(drop2))\n",
    "\n",
    "    ## 3 layer\n",
    "    model.add(tf.keras.layers.Conv2D(384,(3,3),\n",
    "                                   padding='same',\n",
    "                                   kernel_initializer = krnl_initializer)) ## output shape expected - 13*13*384\n",
    "    \n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(384,(3,3),\n",
    "                                   padding='same',\n",
    "                                   kernel_initializer = krnl_initializer)) ## output shape expected - 13*13*384\n",
    "    \n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(256,(3,3),\n",
    "                                   padding='same',\n",
    "                                   kernel_initializer = krnl_initializer)) ## output shape expected - 13*13*256\n",
    "\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2)) ## 6*6*256\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(drop3))\n",
    "\n",
    "\n",
    "    ## Head\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(4096, kernel_initializer = krnl_initializer))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.Dropout(drop4))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(4096, kernel_initializer = krnl_initializer))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.Dropout(drop5))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(256, kernel_initializer = krnl_initializer))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.Dropout(drop6))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(num_classes))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NK2077-9Mxys",
    "outputId": "04b771d0-1e9d-424f-c28e-c0e8dcf2d302"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'fill_mode')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(input_shape, num_classes)\n\u001b[0;32m      2\u001b[0m model\n",
      "Cell \u001b[1;32mIn[16], line 21\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(input_shape, num_classes)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m## Augmentation\u001b[39;00m\n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mRandomRotation((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m0.5\u001b[39m), fill_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m, seed\u001b[38;5;241m=\u001b[39mRANDOM_STATE))\n\u001b[1;32m---> 21\u001b[0m model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mRandomFlip((\u001b[38;5;241m0.2\u001b[39m,\u001b[38;5;241m0.2\u001b[39m), fill_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m, seed\u001b[38;5;241m=\u001b[39mRANDOM_STATE))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m## 1 layer\u001b[39;00m\n\u001b[0;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m96\u001b[39m,(\u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m11\u001b[39m),\n\u001b[0;32m     25\u001b[0m                                strides\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m),\n\u001b[0;32m     26\u001b[0m                                padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     27\u001b[0m                                kernel_initializer \u001b[38;5;241m=\u001b[39m krnl_initializer,\n\u001b[0;32m     28\u001b[0m                                input_shape \u001b[38;5;241m=\u001b[39minput_shape)) \u001b[38;5;66;03m## output shape expected - 55*55*96\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\image_preprocessing.py:430\u001b[0m, in \u001b[0;36mRandomFlip.__init__\u001b[1;34m(self, mode, seed, **kwargs)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39mHORIZONTAL_AND_VERTICAL, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 430\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(seed\u001b[38;5;241m=\u001b[39mseed, force_generator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    431\u001b[0m     base_preprocessing_layer\u001b[38;5;241m.\u001b[39mkeras_kpl_gauge\u001b[38;5;241m.\u001b[39mget_cell(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomFlip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mset(\n\u001b[0;32m    432\u001b[0m         \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    433\u001b[0m     )\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m mode\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py:3812\u001b[0m, in \u001b[0;36mBaseRandomLayer.__init__\u001b[1;34m(self, seed, force_generator, rng_type, **kwargs)\u001b[0m\n\u001b[0;32m   3784\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mtracking\u001b[38;5;241m.\u001b[39mno_automatic_dependency_tracking\n\u001b[0;32m   3785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m   3786\u001b[0m     \u001b[38;5;28mself\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, force_generator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, rng_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   3787\u001b[0m ):\n\u001b[0;32m   3788\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize the BaseRandomLayer.\u001b[39;00m\n\u001b[0;32m   3789\u001b[0m \n\u001b[0;32m   3790\u001b[0m \u001b[38;5;124;03m    Note that the constructor is annotated with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3810\u001b[0m \u001b[38;5;124;03m        *class\u001b[39;00m\n\u001b[0;32m   3811\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3813\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_generator \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mRandomGenerator(\n\u001b[0;32m   3814\u001b[0m         seed, force_generator\u001b[38;5;241m=\u001b[39mforce_generator, rng_type\u001b[38;5;241m=\u001b[39mrng_type\n\u001b[0;32m   3815\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py:340\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[1;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[0;32m    329\u001b[0m allowed_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimplementation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    338\u001b[0m }\n\u001b[0;32m    339\u001b[0m \u001b[38;5;66;03m# Validate optional keyword arguments.\u001b[39;00m\n\u001b[1;32m--> 340\u001b[0m generic_utils\u001b[38;5;241m.\u001b[39mvalidate_kwargs(kwargs, allowed_kwargs)\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# Mutable properties\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;66;03m# Indicates whether the layer's weights are updated during training\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# and whether the layer's updates are run during training.\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(trainable, \u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m     )\n\u001b[0;32m    351\u001b[0m ):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\generic_utils.py:514\u001b[0m, in \u001b[0;36mvalidate_kwargs\u001b[1;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kwarg \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwarg \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_kwargs:\n\u001b[1;32m--> 514\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(error_message, kwarg)\n",
      "\u001b[1;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'fill_mode')"
     ]
    }
   ],
   "source": [
    "model = build_model(input_shape, num_classes)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qfbVxxENjtL"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "checkpoint_path = os.path.join(modelDir, subDir, 'weights_tf_flower')\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    verbose=2,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='auto',\n",
    "    save_freq='epoch',\n",
    "    initial_value_threshold=None\n",
    ")\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=PATIENCE,\n",
    "    verbose=2,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=0\n",
    ")\n",
    "\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=FACTOR_LR,\n",
    "    patience=LR_PATIENCE,\n",
    "    verbose=2,\n",
    "    mode='auto',\n",
    "    min_delta=0.00001,\n",
    "    cooldown=0,\n",
    "    min_lr=0.0,\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WSAiOVPNAHn"
   },
   "source": [
    "## Compile and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIxK-zgxNHpw"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=ALPHA)\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JN_s8DVxOHma",
    "outputId": "a5d9c95b-7232-4a24-845a-70d87e5fa7ab",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    validation_data = test_ds ,\n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    epochs = EPOCHS, verbose=2,\n",
    "                    callbacks=[model_checkpoint,es_callback,lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l0W-VX75PPhj"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMUVfsUARJ5H"
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(model,'model.png', show_shapes=True, show_dtype=True, dpi=96, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8Rkhy27RHMI"
   },
   "outputs": [],
   "source": [
    "history_df1 = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F08aR88JgC7_"
   },
   "outputs": [],
   "source": [
    "history1 = model.fit(train_ds,\n",
    "                    validation_data = test_ds ,\n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    epochs = EPOCHS, verbose=2,\n",
    "                    callbacks=[model_checkpoint,es_callback,lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df2 = pd.DataFrame(history1.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.concat((history_df1,history_df2),ignore_index=True)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_plot_tf_hist(history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
