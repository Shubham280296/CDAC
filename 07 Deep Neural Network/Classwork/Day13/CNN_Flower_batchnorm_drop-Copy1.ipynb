{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "679Lmwt3l1Bk"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Vq1MaJI-4uF"
   },
   "source": [
    "# CNN\n",
    "\n",
    "\n",
    "##  Flower Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iAve6DCL4JH4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###-----------------\n",
    "### Import Libraries\n",
    "###-----------------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils.helper import fn_plot_tf_hist,fn_plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0QFsplWU-4uH"
   },
   "outputs": [],
   "source": [
    "###----------------------\n",
    "### Some basic parameters\n",
    "###----------------------\n",
    "inpDir = '../..\\Classwork/input'\n",
    "outDir = './output'\n",
    "subDir = 'flower_photos'\n",
    "modelDir = './models'\n",
    "logDir = './logs'\n",
    "altName = 'cnn_base'\n",
    "\n",
    "RANDOM_STATE = 24 # for initialization ----- REMEMBER: to remove at the time of promotion to production\n",
    "tf.random.set_seed(RANDOM_STATE) # setting for Tensorflow as well\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "ALPHA = 0.001\n",
    "EPOCHS = 100 # number of cycles to run\n",
    "PATIENCE = 20\n",
    "LR_PATIENCE = 10\n",
    "FACTOR_LR = 0.1\n",
    "BATCH_SIZE = 32 # inline of Training Rows being 60000\n",
    "IMG_HEIGHT = 187\n",
    "IMG_WIDTH = 187\n",
    "\n",
    "\n",
    "# Set parameters for decoration of plots\n",
    "params = {'legend.fontsize' : 'large',\n",
    "          'figure.figsize'  : (15,10),\n",
    "          'axes.labelsize'  : 'x-large',\n",
    "          'axes.titlesize'  :'x-large',\n",
    "          'xtick.labelsize' :'large',\n",
    "          'ytick.labelsize' :'large',\n",
    "         }\n",
    "\n",
    "CMAP = plt.cm.coolwarm\n",
    "\n",
    "plt.rcParams.update(params) # update rcParams\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid') # plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qbHlymTEdxG"
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "x2uh0xZm-4uJ",
    "outputId": "67ab73a8-e290-4167-aff5-e22e047ac7c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
      "228813984/228813984 [==============================] - 16s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndata_dir = os.path.join(inpDir, subDir)\\ndata_dir\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "\n",
    "data_dir = tf.keras.utils.get_file(origin=dataset_url,\n",
    "                                   fname='flower_photos',\n",
    "                                   untar=True)\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "'''\n",
    "data_dir = os.path.join(inpDir, subDir)\n",
    "data_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dMpgmBvErj2"
   },
   "source": [
    "## Creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J8Shk8Fi-4uL",
    "outputId": "8e654aec-a9f1-442c-abf5-1df91814ab81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2936 files for training.\n",
      "Found 3670 files belonging to 5 classes.\n",
      "Using 734 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# create training data\n",
    "train_ds =tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir, # path the the data directory\n",
    "    validation_split=TEST_SIZE, # what ratio of validation data\n",
    "    subset='training', # purpose\n",
    "    seed=RANDOM_STATE,\n",
    "    image_size=[IMG_HEIGHT, IMG_WIDTH], ## @@@ WHAT!\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "# test data\n",
    "test_ds =tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir, # path the the data directory\n",
    "    validation_split=TEST_SIZE, # what ratio of validation data\n",
    "    subset='validation', # purpose\n",
    "    seed=RANDOM_STATE,\n",
    "    image_size=[IMG_HEIGHT, IMG_WIDTH], ## @@@ WHAT!\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FP9Jk9Lf-4uL",
    "outputId": "ebd8967f-64ca-4c85-a602-3e6dfb80c504"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is it picking class names\n",
    "class_names = train_ds.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CbxIr7tRAhOj",
    "outputId": "74f0d873-0032-4312-8095-365b62668188"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'daisy', 1: 'dandelion', 2: 'roses', 3: 'sunflowers', 4: 'tulips'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = {k:v for k,v in enumerate(class_names)}\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQ-gvaS-EvN9"
   },
   "source": [
    "## Visualize data in train_ds and test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "klChSP0b-4uM",
    "outputId": "c58fd433-4923-4815-f9ff-694776a12ec7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure(figsize=(15,8))\\n\\nfor images, labels in train_ds.take(1):\\n    for i in range (BATCH_SIZE):\\n        plt.subplot(int(BATCH_SIZE/8), 8, i +1)\\n        plt.grid(False)\\n        plt.imshow(images[i].numpy().astype('uint8'))\\n        plt.title(class_names[labels[i]])\\n        plt.axis('off')\\n    plt.tight_layout()\\nplt.show()\\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range (BATCH_SIZE):\n",
    "        plt.subplot(int(BATCH_SIZE/8), 8, i +1)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i].numpy().astype('uint8'))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "b97a_uKg-4uM",
    "outputId": "085058e3-0241-4cf7-812f-2e23440e55fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure(figsize=(15,8))\\n\\nfor images, labels in test_ds.take(1): # get me one batch\\n\\n    for i in range (BATCH_SIZE): # loop over batch\\n\\n        plt.subplot(int(BATCH_SIZE/8), 8, i +1) # access the axis\\n\\n        plt.grid(False) # no to grid\\n\\n        plt.imshow(images[i].numpy().astype('uint8')) # show image convert to numpy and int\\n\\n        plt.title(class_names[labels[i]])\\n\\n        plt.axis('off')\\n\\n    plt.tight_layout()\\n\\nplt.show()\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "for images, labels in test_ds.take(1): # get me one batch\n",
    "\n",
    "    for i in range (BATCH_SIZE): # loop over batch\n",
    "\n",
    "        plt.subplot(int(BATCH_SIZE/8), 8, i +1) # access the axis\n",
    "\n",
    "        plt.grid(False) # no to grid\n",
    "\n",
    "        plt.imshow(images[i].numpy().astype('uint8')) # show image convert to numpy and int\n",
    "\n",
    "        plt.title(class_names[labels[i]])\n",
    "\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAodZH89EzY2"
   },
   "source": [
    "## To check whether data is balanced or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "6C862mXf-4uI",
    "outputId": "cd94477f-3af5-478f-a398-473c25be7c9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef fn_plot_label(tr_ds, ts_ds):\\n\\n    plt.figure(figsize = (15,5)) # instantiate the figure\\n\\n    plt.subplot(1,2,1) # first out of 2\\n\\n    train_labels = tf.concat([lbl for img, lbl in tr_ds], axis = 0).numpy() # get the labels\\n\\n    unique, _, counts = tf.unique_with_counts(train_labels) # get counts\\n\\n    plt.bar(range(len(unique)), counts, align='center', color = 'DarkBlue') # barplot the counts\\n\\n    plt.xticks(range(len(unique)), class_names)\\n\\n    plt.title('Training Set')\\n\\n    plt.subplot(1,2,2)\\n\\n    test_labels = tf.concat([lbl for img, lbl in ts_ds], axis = 0).numpy()\\n\\n    unique, _, counts = tf.unique_with_counts(test_labels)\\n\\n    plt.bar(range(len(unique)), counts, align='center', color = 'Orange')\\n\\n    plt.xticks(range(len(unique)), class_names)\\n\\n    plt.title('Test Set')\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def fn_plot_label(tr_ds, ts_ds):\n",
    "\n",
    "    plt.figure(figsize = (15,5)) # instantiate the figure\n",
    "\n",
    "    plt.subplot(1,2,1) # first out of 2\n",
    "\n",
    "    train_labels = tf.concat([lbl for img, lbl in tr_ds], axis = 0).numpy() # get the labels\n",
    "\n",
    "    unique, _, counts = tf.unique_with_counts(train_labels) # get counts\n",
    "\n",
    "    plt.bar(range(len(unique)), counts, align='center', color = 'DarkBlue') # barplot the counts\n",
    "\n",
    "    plt.xticks(range(len(unique)), class_names)\n",
    "\n",
    "    plt.title('Training Set')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "\n",
    "    test_labels = tf.concat([lbl for img, lbl in ts_ds], axis = 0).numpy()\n",
    "\n",
    "    unique, _, counts = tf.unique_with_counts(test_labels)\n",
    "\n",
    "    plt.bar(range(len(unique)), counts, align='center', color = 'Orange')\n",
    "\n",
    "    plt.xticks(range(len(unique)), class_names)\n",
    "\n",
    "    plt.title('Test Set')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "A6hRkrIp-4uN"
   },
   "outputs": [],
   "source": [
    "# fn_plot_label(train_ds, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size = tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0PW-0DJE68-"
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4izZWt8-4uN",
    "outputId": "0d640a66-7efa-476c-a08d-817a727870b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((190, 190, 3), 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "num_classes = len(class_names)\n",
    "input_shape, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "v5SgPGyt-4uN"
   },
   "outputs": [],
   "source": [
    "def build_model (input_shape, num_classes):\n",
    "    \n",
    "    krnl_initializer = tf.keras.initializers.GlorotUniform()\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    ## increasing dropout rate\n",
    "    drop1 = 0.1\n",
    "    drop2 = 0.1\n",
    "    drop3 = 0.2\n",
    "    drop4 = 0.2\n",
    "    drop5 = 0.3\n",
    "    drop6 = 0.3\n",
    "    drop7 = 0.4\n",
    "    drop8 = 0.4\n",
    "\n",
    "    ## preprocessing (scaling)\n",
    "    model.add(tf.keras.layers.Rescaling(1./255.))\n",
    "\n",
    "    ## Augmentation\n",
    "\n",
    "    model.add(tf.keras.layers.RandomZoom((0.2,0.2), fill_mode = 'nearest', seed=RANDOM_STATE))\n",
    "\n",
    "    ## 1 layer\n",
    "    model.add(tf.keras.layers.Conv2D(32,(5,5),\n",
    "                                     strides=(2, 2),\n",
    "                                     kernel_initializer = krnl_initializer,\n",
    "                                     input_shape =input_shape)) ## output shape expected - 92*92*32\n",
    "\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2))) ## 46*46*32\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(drop1))\n",
    "\n",
    "    ## 2 layer\n",
    "    model.add(tf.keras.layers.Conv2D(64,3,\n",
    "                                     kernel_initializer = krnl_initializer)) ## output shape expected - 44*44*64\n",
    "\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2))) ## 22*22*256\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(drop2))\n",
    "\n",
    "    ## 3 layer\n",
    "    model.add(tf.keras.layers.Conv2D(128,(3,3),\n",
    "                                     kernel_initializer = krnl_initializer)) ## output shape expected - 20*20*512\n",
    "\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2))) ## 10*10*128\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(drop3))\n",
    "\n",
    "    ## 4 layer\n",
    "    model.add(tf.keras.layers.Conv2D(256,(3,3),\n",
    "                                     kernel_initializer = krnl_initializer)) ## output shape expected - 8*8*256\n",
    "\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2))) ## 4*4*256\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(drop4))\n",
    "\n",
    "\n",
    "    ## 5 layer\n",
    "    model.add(tf.keras.layers.Conv2D(512,(3,3),\n",
    "                                     kernel_initializer = krnl_initializer)) ## output shape expected - 2*2*512\n",
    "\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(drop5))\n",
    "\n",
    "\n",
    "    ## Head\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(512, kernel_initializer = krnl_initializer))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.Dropout(drop6))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(128, kernel_initializer = krnl_initializer))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.Dropout(drop7))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(32, kernel_initializer = krnl_initializer))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(tf.keras.layers.Dropout(drop8))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(num_classes))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NK2077-9Mxys",
    "outputId": "04b771d0-1e9d-424f-c28e-c0e8dcf2d302"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x2a6c2f72cd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(input_shape, num_classes)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9qfbVxxENjtL"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = './weights_tf_flower'\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    verbose=2,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='auto',\n",
    "    save_freq='epoch',\n",
    "    initial_value_threshold=None\n",
    ")\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=PATIENCE,\n",
    "    verbose=2,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=0\n",
    ")\n",
    "\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=FACTOR_LR,\n",
    "    patience=LR_PATIENCE,\n",
    "    verbose=2,\n",
    "    mode='auto',\n",
    "    min_delta=0.00001,\n",
    "    cooldown=0,\n",
    "    min_lr=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WSAiOVPNAHn"
   },
   "source": [
    "## Compile and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "NIxK-zgxNHpw"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=ALPHA)\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JN_s8DVxOHma",
    "outputId": "a5d9c95b-7232-4a24-845a-70d87e5fa7ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\keras\\src\\initializers\\initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator.DAI-PC2\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.86715, saving model to .\\weights_tf_flower\n",
      "92/92 - 84s - loss: 1.7894 - accuracy: 0.2473 - val_loss: 1.8671 - val_accuracy: 0.2384 - lr: 0.0010 - 84s/epoch - 910ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.86715\n",
      "92/92 - 72s - loss: 1.4712 - accuracy: 0.3573 - val_loss: 2.0527 - val_accuracy: 0.2561 - lr: 0.0010 - 72s/epoch - 786ms/step\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.86715\n",
      "92/92 - 73s - loss: 1.3561 - accuracy: 0.4384 - val_loss: 2.3980 - val_accuracy: 0.2452 - lr: 0.0010 - 73s/epoch - 790ms/step\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.86715\n",
      "92/92 - 72s - loss: 1.2875 - accuracy: 0.4653 - val_loss: 2.1124 - val_accuracy: 0.3297 - lr: 0.0010 - 72s/epoch - 787ms/step\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 1.86715 to 1.51805, saving model to .\\weights_tf_flower\n",
      "92/92 - 73s - loss: 1.2193 - accuracy: 0.5109 - val_loss: 1.5180 - val_accuracy: 0.4169 - lr: 0.0010 - 73s/epoch - 796ms/step\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 1.51805 to 1.15479, saving model to .\\weights_tf_flower\n",
      "92/92 - 73s - loss: 1.1683 - accuracy: 0.5436 - val_loss: 1.1548 - val_accuracy: 0.5559 - lr: 0.0010 - 73s/epoch - 793ms/step\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.15479\n",
      "92/92 - 73s - loss: 1.1412 - accuracy: 0.5436 - val_loss: 1.2723 - val_accuracy: 0.5191 - lr: 0.0010 - 73s/epoch - 791ms/step\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 1.15479 to 1.14396, saving model to .\\weights_tf_flower\n",
      "92/92 - 72s - loss: 1.1205 - accuracy: 0.5678 - val_loss: 1.1440 - val_accuracy: 0.5450 - lr: 0.0010 - 72s/epoch - 779ms/step\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss improved from 1.14396 to 0.99581, saving model to .\\weights_tf_flower\n",
      "92/92 - 71s - loss: 1.0887 - accuracy: 0.5780 - val_loss: 0.9958 - val_accuracy: 0.6172 - lr: 0.0010 - 71s/epoch - 767ms/step\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.99581\n",
      "92/92 - 69s - loss: 1.0528 - accuracy: 0.5920 - val_loss: 1.0894 - val_accuracy: 0.5681 - lr: 0.0010 - 69s/epoch - 751ms/step\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.99581\n",
      "92/92 - 69s - loss: 1.0767 - accuracy: 0.5872 - val_loss: 1.3357 - val_accuracy: 0.5259 - lr: 0.0010 - 69s/epoch - 746ms/step\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.99581\n",
      "92/92 - 69s - loss: 1.0673 - accuracy: 0.5807 - val_loss: 1.2236 - val_accuracy: 0.5409 - lr: 0.0010 - 69s/epoch - 750ms/step\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss improved from 0.99581 to 0.98433, saving model to .\\weights_tf_flower\n",
      "92/92 - 70s - loss: 1.0459 - accuracy: 0.5960 - val_loss: 0.9843 - val_accuracy: 0.6144 - lr: 0.0010 - 70s/epoch - 765ms/step\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.98433\n",
      "92/92 - 69s - loss: 1.0323 - accuracy: 0.5995 - val_loss: 1.2619 - val_accuracy: 0.4550 - lr: 0.0010 - 69s/epoch - 748ms/step\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.98433\n",
      "92/92 - 69s - loss: 1.0167 - accuracy: 0.6005 - val_loss: 1.1039 - val_accuracy: 0.5695 - lr: 0.0010 - 69s/epoch - 755ms/step\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.98433\n",
      "92/92 - 72s - loss: 0.9974 - accuracy: 0.6066 - val_loss: 1.0171 - val_accuracy: 0.5899 - lr: 0.0010 - 72s/epoch - 778ms/step\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.98433\n",
      "92/92 - 70s - loss: 0.9726 - accuracy: 0.6165 - val_loss: 1.0477 - val_accuracy: 0.5899 - lr: 0.0010 - 70s/epoch - 759ms/step\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.98433\n",
      "92/92 - 69s - loss: 1.0052 - accuracy: 0.6080 - val_loss: 1.4121 - val_accuracy: 0.5313 - lr: 0.0010 - 69s/epoch - 749ms/step\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.98433\n",
      "92/92 - 69s - loss: 0.9696 - accuracy: 0.6236 - val_loss: 2.7128 - val_accuracy: 0.2684 - lr: 0.0010 - 69s/epoch - 749ms/step\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.98433\n",
      "92/92 - 68s - loss: 0.9574 - accuracy: 0.6175 - val_loss: 1.4897 - val_accuracy: 0.4387 - lr: 0.0010 - 68s/epoch - 743ms/step\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss improved from 0.98433 to 0.95456, saving model to .\\weights_tf_flower\n",
      "92/92 - 70s - loss: 0.9652 - accuracy: 0.6185 - val_loss: 0.9546 - val_accuracy: 0.6294 - lr: 0.0010 - 70s/epoch - 761ms/step\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss improved from 0.95456 to 0.92494, saving model to .\\weights_tf_flower\n",
      "92/92 - 70s - loss: 0.9478 - accuracy: 0.6158 - val_loss: 0.9249 - val_accuracy: 0.6240 - lr: 0.0010 - 70s/epoch - 763ms/step\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss improved from 0.92494 to 0.91533, saving model to .\\weights_tf_flower\n",
      "92/92 - 71s - loss: 0.9432 - accuracy: 0.6339 - val_loss: 0.9153 - val_accuracy: 0.6567 - lr: 0.0010 - 71s/epoch - 773ms/step\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss improved from 0.91533 to 0.87517, saving model to .\\weights_tf_flower\n",
      "92/92 - 72s - loss: 0.9215 - accuracy: 0.6325 - val_loss: 0.8752 - val_accuracy: 0.6322 - lr: 0.0010 - 72s/epoch - 788ms/step\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.87517\n",
      "92/92 - 71s - loss: 0.9286 - accuracy: 0.6356 - val_loss: 0.8926 - val_accuracy: 0.6580 - lr: 0.0010 - 71s/epoch - 771ms/step\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.87517\n",
      "92/92 - 70s - loss: 0.9143 - accuracy: 0.6488 - val_loss: 1.2935 - val_accuracy: 0.5327 - lr: 0.0010 - 70s/epoch - 763ms/step\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.87517\n",
      "92/92 - 70s - loss: 0.9293 - accuracy: 0.6369 - val_loss: 1.1767 - val_accuracy: 0.5817 - lr: 0.0010 - 70s/epoch - 756ms/step\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.87517\n",
      "92/92 - 70s - loss: 0.9127 - accuracy: 0.6458 - val_loss: 0.9035 - val_accuracy: 0.6580 - lr: 0.0010 - 70s/epoch - 760ms/step\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.87517\n",
      "92/92 - 69s - loss: 0.8960 - accuracy: 0.6448 - val_loss: 0.8942 - val_accuracy: 0.6540 - lr: 0.0010 - 69s/epoch - 753ms/step\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.87517\n",
      "92/92 - 72s - loss: 0.8986 - accuracy: 0.6471 - val_loss: 1.4215 - val_accuracy: 0.4591 - lr: 0.0010 - 72s/epoch - 777ms/step\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss improved from 0.87517 to 0.83258, saving model to .\\weights_tf_flower\n",
      "92/92 - 72s - loss: 0.9100 - accuracy: 0.6516 - val_loss: 0.8326 - val_accuracy: 0.6730 - lr: 0.0010 - 72s/epoch - 783ms/step\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.83258\n",
      "92/92 - 71s - loss: 0.8871 - accuracy: 0.6509 - val_loss: 0.8373 - val_accuracy: 0.6771 - lr: 0.0010 - 71s/epoch - 777ms/step\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.83258\n",
      "92/92 - 72s - loss: 0.8967 - accuracy: 0.6424 - val_loss: 1.1588 - val_accuracy: 0.5708 - lr: 0.0010 - 72s/epoch - 786ms/step\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.83258\n",
      "92/92 - 70s - loss: 0.8757 - accuracy: 0.6536 - val_loss: 0.8537 - val_accuracy: 0.6567 - lr: 0.0010 - 70s/epoch - 761ms/step\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.83258\n",
      "92/92 - 70s - loss: 0.8853 - accuracy: 0.6587 - val_loss: 0.9599 - val_accuracy: 0.6253 - lr: 0.0010 - 70s/epoch - 765ms/step\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.83258\n",
      "92/92 - 72s - loss: 0.8529 - accuracy: 0.6635 - val_loss: 1.3367 - val_accuracy: 0.5300 - lr: 0.0010 - 72s/epoch - 784ms/step\n",
      "Epoch 37/100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    validation_data = test_ds ,\n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    epochs = EPOCHS, verbose=2,\n",
    "                    callbacks=[model_checkpoint,es_callback,lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l0W-VX75PPhj"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMUVfsUARJ5H"
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(model,'model.png', show_shapes=True, show_dtype=True, dpi=96, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8Rkhy27RHMI"
   },
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "fn_plot_tf_hist(history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F08aR88JgC7_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
